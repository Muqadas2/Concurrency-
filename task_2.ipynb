{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPV3NHWfqYx7GBsbH+fxmrA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Muqadas2/Concurrency-/blob/main/task_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Write a function in Python that takes two vectors as input (weight and feature vector) and\n",
        "returns the logistic regression prediction for that input.**\n",
        "\n",
        "Logistic regression uses the sigmoid function to transform a linear combination of weights and features into a probability."
      ],
      "metadata": {
        "id": "9lFeVj8ft65K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unr_XfTesmiq",
        "outputId": "532bad41-7b56-4283-b7d4-ea5048855e35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: 0.7310585786300049\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "# sigmoid function\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "# function that calculate z for each example and sigmoid functions uses it\n",
        "def logistic_regression_predict(w, x):\n",
        "    \"\"\"\n",
        "    Predicts the probability using logistic regression.\n",
        "\n",
        "    w: Weight vector\n",
        "    x: Feature vector\n",
        "\n",
        "    Returns ==> Probability (between 0 and 1)\n",
        "    \"\"\"\n",
        "    z = np.dot(w, x)  # Compute the linear combination\n",
        "    return sigmoid(z)\n",
        "\n",
        "# Example Usage:\n",
        "w = np.array([0.5, -0.2, 0.3])  # Example weights\n",
        "x = np.array([1, 2, 3])         # Example feature vector\n",
        "print(\"Prediction:\", logistic_regression_predict(w, x))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Write a function in Python that takes a vector of predictions and a vector of actual values as\n",
        "input and returns the Logistic Loss.**\n",
        "\n"
      ],
      "metadata": {
        "id": "1ex-jf6jB4n8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def logistic_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Computes logistic loss (binary cross-entropy).\n",
        "\n",
        "    y_true: Actual values (0 or 1)\n",
        "    y_pred: Predicted probabilities\n",
        "\n",
        "    Returns: Logistic loss\n",
        "    \"\"\"\n",
        "    y_pred = np.clip(y_pred, 1e-9, 1 - 1e-9)  # Avoid log(0) issues\n",
        "    loss = -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
        "    return loss\n",
        "\n",
        "# Example Usage:\n",
        "y_true = np.array([1, 0, 1])  # Actual labels\n",
        "y_pred = np.array([0.8, 0.2, 0.6])  # Predicted probabilities\n",
        "print(\"Logistic Loss:\", logistic_loss(y_true, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgvloDx8CHZ6",
        "outputId": "8bec549c-b421-4244-b009-ee25b89b88cf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Loss: 0.3190375754648034\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Write a function in Python that takes a vector of predictions and training data as input and\n",
        "returns the Gradient of Logistic Loss.**\n",
        "\n"
      ],
      "metadata": {
        "id": "vtM52fomCic7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def logistic_loss_gradient(y_true, y_pred, X):\n",
        "    \"\"\"\n",
        "    Computes the gradient of logistic loss.\n",
        "\n",
        "    y_true: Actual labels\n",
        "    y_pred: Predicted probabilities\n",
        "    X: Training data\n",
        "\n",
        "    Returns: Gradient vector\n",
        "    \"\"\"\n",
        "    n = len(y_true)\n",
        "    return (1 / n) * np.dot(X.T, (y_pred - y_true))\n",
        "\n",
        "# Example Usage:\n",
        "X = np.array([[1, 2], [2, 3], [3, 4]])  # Features\n",
        "y_pred = np.array([0.8, 0.2, 0.6])  # Predicted probabilities\n",
        "y_true = np.array([1, 0, 1])  # Actual labels\n",
        "print(\"Gradient of Logistic Loss:\", logistic_loss_gradient(y_true, y_pred, X))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYyyWya5CtHS",
        "outputId": "125f4479-a39e-4c6d-d538-9478b5703c70"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient of Logistic Loss: [-0.33333333 -0.46666667]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Write a function in Python that implements the gradient descent algorithm for logistic\n",
        "regression. The function should take a weight vector, gradient of logistic loss and a stopping\n",
        "criterion as input and return the optimized weight vector**\n",
        "\n"
      ],
      "metadata": {
        "id": "S_7Qy9cXC0ct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def gradient_descent(w, X, y_true, learning_rate=0.1, max_iters=1000, tol=1e-6):\n",
        "    \"\"\"\n",
        "    Implements gradient descent for logistic regression.\n",
        "\n",
        "    w: Initial weight vector\n",
        "    X: Training features\n",
        "    y_true: Actual labels\n",
        "    learning_rate: Learning rate\n",
        "    max_iters: Max iterations\n",
        "    tol: Tolerance for stopping\n",
        "\n",
        "    Returns: Optimized weight vector\n",
        "    \"\"\"\n",
        "    for i in range(max_iters):\n",
        "        y_pred = sigmoid(np.dot(X, w))  # Compute predictions\n",
        "        grad = logistic_loss_gradient(y_true, y_pred, X)  # Compute gradient\n",
        "        w_new = w - learning_rate * grad  # Update weights\n",
        "\n",
        "        # Stop if the change is small\n",
        "        if np.linalg.norm(w_new - w) < tol:\n",
        "            break\n",
        "\n",
        "        w = w_new\n",
        "    return w\n",
        "\n",
        "\n",
        "def sigmoid(z):\n",
        "    \"\"\"Compute the sigmoid function.\"\"\"\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "def logistic_regression_predict(w, X):\n",
        "    \"\"\"Compute logistic regression predictions.\"\"\"\n",
        "    return sigmoid(np.dot(X, w))\n",
        "\n",
        "\n",
        "# Example Usage:\n",
        "w_init = np.zeros(2)  # Initial weights\n",
        "X_train = np.array([[1, 2], [2, 3], [3, 4]])  # Feature data\n",
        "y_train = np.array([1, 0, 1])  # Actual labels\n",
        "optimized_w = gradient_descent(w_init, X_train, y_train)\n",
        "print(\"Optimized Weights:\", optimized_w)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldg7WPLdC67_",
        "outputId": "0b7aaf21-b4b9-4a2a-cf0b-63a3db36f029"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized Weights: [-0.41676309  0.50183428]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Use the functions created in the previous parts to apply logistic regression on the Iris Dataset.\n",
        "Use one vs rest approach to classify for each Iris flower species in the dataset.**\n",
        "\n"
      ],
      "metadata": {
        "id": "5Yod2LyqFDA4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "# Load Iris dataset\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data  # Features\n",
        "y = iris.target  # Labels\n",
        "\n",
        "# Convert labels to One-vs-Rest format (binary classification for each class)\n",
        "lb = LabelBinarizer()\n",
        "y_bin = lb.fit_transform(y)\n",
        "\n",
        "# Train logistic regression model for each class\n",
        "num_classes = y_bin.shape[1]\n",
        "weights = []\n",
        "\n",
        "for i in range(num_classes):\n",
        "    print(f\"Training logistic regression for class {i}...\")\n",
        "    w_init = np.zeros(X.shape[1])  # Initialize weights\n",
        "    w_opt = gradient_descent(w_init, X, y_bin[:, i], learning_rate=0.1, max_iters=500)\n",
        "    weights.append(w_opt)\n",
        "\n",
        "# Make predictions\n",
        "predictions = np.array([logistic_regression_predict(w, X) for w in weights]).T\n",
        "\n",
        "final_preds = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy = np.mean(final_preds == y)\n",
        "print(\"Logistic Regression Accuracy on Iris Dataset:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qX38sfKlFKaj",
        "outputId": "71f3e02a-69a3-424e-d67f-891c24704752"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training logistic regression for class 0...\n",
            "Training logistic regression for class 1...\n",
            "Training logistic regression for class 2...\n",
            "Logistic Regression Accuracy on Iris Dataset: 0.96\n"
          ]
        }
      ]
    }
  ]
}